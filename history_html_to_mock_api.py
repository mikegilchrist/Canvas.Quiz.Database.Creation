#!/usr/bin/env python3
#
# Date: 2026-01-23
# Version: 1.0.0
# Purpose: Convert an exported Canvas Classic Quizzes SpeedGrader "quiz history" HTML page into mock Canvas API JSON files for offline testing, while anonymizing user information.
# Usage: history_html_to_mock_api.py INPUT.html OUTDIR
#        history_html_to_mock_api.py INPUT.html OUTDIR --student-name "Smith, John" --student-id 1234567890
#        history_html_to_mock_api.py INPUT.html OUTDIR --dry-run --verbose
#        history_html_to_mock_api.py --help
# Input: Exported SpeedGrader quiz history.html.
#        File is generated by visiting and saving a speedgrader webpage 'as html' in a browser.
#        The created folders and files include <ASSIGNMENT_NAME>_files/history.html 
# Output: Three JSON files in OUTDIR: mock_quiz_submissions.json, mock_quiz_questions.json, mock_quiz_submission_<submission_id>_questions.json
# Chat name: Canvas SpeedGrader Archive
# GPT Model: GPT-5.2 Thinking
# Attribution: Generated by Michael Gilchrist in collaboration with ChatGPT.

import argparse
import json
import os
import sys

try:
    from bs4 import BeautifulSoup
except Exception as e:
    sys.stderr.write("Error: BeautifulSoup is required. Install with: pip install beautifulsoup4\n")
    sys.stderr.write(f"Details: {e}\n")
    sys.exit(2)


def vlog(verbose, msg):
    if verbose:
        sys.stderr.write(msg.rstrip() + "\n")


def ensure_outdir(outdir):
    os.makedirs(outdir, exist_ok=True)


def extract_ids_from_action(action_url):
    # Expected pattern: /courses/{course_id}/quizzes/{quiz_id}/submissions/{submission_id}
    parts = [p for p in action_url.split("/") if p]

    def idx(token):
        try:
            return parts.index(token)
        except ValueError:
            return None

    i_courses = idx("courses")
    i_quizzes = idx("quizzes")
    i_subs = idx("submissions")

    course_id = parts[i_courses + 1] if i_courses is not None and i_courses + 1 < len(parts) else None
    quiz_id = parts[i_quizzes + 1] if i_quizzes is not None and i_quizzes + 1 < len(parts) else None
    submission_id = parts[i_subs + 1] if i_subs is not None and i_subs + 1 < len(parts) else None
    return course_id, quiz_id, submission_id


def get_text(el):
    if el is None:
        return ""
    return el.get_text(" ", strip=True)


def parse_first_ints_in_text(txt):
    # Return list of integers found by token scanning (no regex)
    nums = []
    for tok in txt.replace(":", " ").replace("/", " ").replace(".", " ").split():
        if tok.isdigit():
            nums.append(int(tok))
    return nums


def parse_score_and_total_points(soup):
    # "Score for this quiz: 83 out of 83"
    score_div = soup.find("div", class_="quiz_score")
    if score_div is None:
        return None, None, None

    txt = get_text(score_div)
    nums = parse_first_ints_in_text(txt)
    score = nums[0] if len(nums) >= 1 else None
    total = nums[1] if len(nums) >= 2 else None

    # In the export, the "Submitted ..." line often follows as the next sibling div.
    end_time = None
    sib = score_div.find_next_sibling("div")
    if sib is not None:
        # Keep as raw human-readable string in mock
        end_time = get_text(sib) or None

    return score, total, end_time


def parse_time_spent_seconds(soup):
    # "This attempt took 535 minutes."
    dur = soup.find("div", class_="quiz_duration")
    if dur is None:
        return None
    nums = parse_first_ints_in_text(get_text(dur))
    if not nums:
        return None
    minutes = nums[0]
    return minutes * 60


def inner_html(el):
    if el is None:
        return ""
    return "".join(str(c) for c in el.contents)


def parse_question_number(question_name_text):
    # Expected "Question 1"
    if not question_name_text:
        return None
    parts = question_name_text.split()
    for p in parts:
        if p.isdigit():
            return int(p)
    return None


def parse_user_points(qnode):
    # "12 / 12 pts"
    up = qnode.find("div", class_="user_points")
    if up is None:
        return None, None
    nums = parse_first_ints_in_text(get_text(up))
    if len(nums) >= 2:
        earned = nums[0]
        possible = nums[1]
        return earned, possible
    return None, None


def main():
    ap = argparse.ArgumentParser(description="Convert exported SpeedGrader quiz history HTML to mock Canvas API JSON.")
    ap.add_argument("input_html", help="Exported SpeedGrader quiz history HTML file")
    ap.add_argument("outdir", help="Output directory for JSON files")

    ap.add_argument("--student-name", default="Smith, John", help="Placeholder student display name")
    ap.add_argument("--student-id", type=int, default=1234567890, help="Placeholder student Canvas user_id")
    ap.add_argument("--dry-run", action="store_true", help="Do not write files")
    ap.add_argument("--verbose", action="store_true", help="Verbose logging")

    args = ap.parse_args()

    ensure_outdir(args.outdir)

    vlog(args.verbose, f"Reading HTML: {args.input_html}")
    with open(args.input_html, "r", encoding="utf-8", errors="replace") as f:
        soup = BeautifulSoup(f.read(), "html.parser")

    form = soup.find("form", id="update_history_form")
    action = form.get("action") if form else None
    if not action:
        sys.stderr.write("Error: Could not find form#update_history_form with an action URL.\n")
        sys.exit(1)

    course_id, quiz_id, submission_id = extract_ids_from_action(action)
    if not quiz_id or not submission_id:
        sys.stderr.write("Error: Could not parse quiz_id and submission_id from form action URL.\n")
        sys.exit(1)

    # Quiz title
    quiz_name = None
    header = soup.find("header", class_="quiz-header")
    if header is not None:
        h2 = header.find("h2")
        quiz_name = get_text(h2) or None

    score, total_points, end_time = parse_score_and_total_points(soup)
    time_spent = parse_time_spent_seconds(soup)

    # Build mock "quiz_submissions" list payload (minimal)
    mock_quiz_submissions = [{
        "id": int(submission_id),
        "user_id": int(args.student_id),
        "quiz_id": int(quiz_id),
        "started_at": None,
        "finished_at": end_time,
        "time_spent": time_spent,
        "score": score,
        "quiz": {
            "id": int(quiz_id),
            "title": quiz_name
        },
        "user": {
            "id": int(args.student_id),
            "name": args.student_name
        }
    }]

    # Parse questions
    questions_div = soup.find("div", id="questions")
    if questions_div is None:
        sys.stderr.write("Error: Could not find div#questions.\n")
        sys.exit(1)

    qnodes = questions_div.find_all("div", class_="display_question")

    mock_quiz_questions = []
    mock_submission_questions = []

    for qnode in qnodes:
        dom_id = qnode.get("id")  # e.g., "question_6087628"
        question_id = dom_id[len("question_"):] if dom_id and dom_id.startswith("question_") else dom_id
        if not question_id:
            continue

        qname = qnode.find("span", class_="question_name")
        qnum = parse_question_number(get_text(qname))

        aqid_span = qnode.find("span", class_="assessment_question_id")
        assessment_question_id = get_text(aqid_span) or None

        earned, possible = parse_user_points(qnode)

        qt = qnode.find("div", class_="question_text")
        question_text_html = inner_html(qt).strip()

        # Student response HTML
        response_html = ""
        answers = qnode.find("div", class_="answers")
        if answers is not None:
            resp = answers.find("div", class_="quiz_response_text")
            if resp is not None:
                response_html = inner_html(resp).strip()

        # Key: general feedback-like text
        key_html = ""
        qc = qnode.find("div", class_="quiz_comment")
        if qc is not None:
            key_html = inner_html(qc).strip()

        # Instructor question definition mock
        mock_quiz_questions.append({
            "id": int(question_id),
            "position": qnum,
            "question_type": "unknown",
            "question_text": question_text_html,
            "points_possible": possible,
            "neutral_comments": key_html,
            "assessment_question_id": assessment_question_id
        })

        # Submission-question mock (what student answered)
        # Canvas "answer" varies by question type; for offline tests we store a minimal object.
        mock_submission_questions.append({
            "quiz_question": {"id": int(question_id)},
            "answer": {
                "format": "html_fragment",
                "value": response_html
            },
            "earned_points": earned,
            "points_possible": possible
        })

    # Output paths
    p_subs = os.path.join(args.outdir, "mock_quiz_submissions.json")
    p_qs = os.path.join(args.outdir, "mock_quiz_questions.json")
    p_sqs = os.path.join(args.outdir, f"mock_quiz_submission_{submission_id}_questions.json")

    vlog(args.verbose, f"Will write: {p_subs}")
    vlog(args.verbose, f"Will write: {p_qs}")
    vlog(args.verbose, f"Will write: {p_sqs}")

    if args.dry_run:
        sys.stderr.write("Dry-run: not writing files.\n")
        sys.exit(0)

    with open(p_subs, "w", encoding="utf-8") as f:
        json.dump(mock_quiz_submissions, f, ensure_ascii=True, indent=2)

    with open(p_qs, "w", encoding="utf-8") as f:
        json.dump(mock_quiz_questions, f, ensure_ascii=True, indent=2)

    with open(p_sqs, "w", encoding="utf-8") as f:
        json.dump(mock_submission_questions, f, ensure_ascii=True, indent=2)

    vlog(args.verbose, "Done.")


if __name__ == "__main__":
    main()
