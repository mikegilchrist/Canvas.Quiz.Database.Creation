#!/usr/bin/env python3
# ============================================================================
# Script:       batch_reports.py
# Version:      1.0.0
# Date:         2026-02-19
# Purpose:      Download Student Analysis (or Item Analysis) CSV reports for
#               all published quizzes in a Canvas course.
#
# Fetches the quiz list, filters to published assignment-type quizzes by
# default, then runs the report_to_csv workflow for each one.
#
# Usage:        batch_reports.py COURSE_ID --base-url URL
#                   [--token TOKEN | --token-file FILE]
#                   [--outdir DIR] [--report-type TYPE]
#                   [--all-versions] [--poll-interval SEC]
#                   [--keep-newlines] [--anonymize]
#                   [--include-surveys] [--quiz-ids ID [ID ...]]
#                   [--dry-run] [--verbose] [--help]
#
# Input:        Canvas API token + course_id
# Output:       One CSV per quiz in --outdir (default: output/CSV)
#
# Options:
#   --base-url URL          Canvas instance URL (required)
#   --token TOKEN           Inline API token
#   --token-file FILE       Path to file containing API token
#   --outdir DIR            Output directory (default: output/CSV)
#   --report-type TYPE      student_analysis (default) or item_analysis
#   --all-versions          Include all submission attempts
#   --poll-interval SEC     Seconds between progress polls (default: 5)
#   --keep-newlines         Keep embedded newlines in CSV fields
#   --anonymize             Replace student PII with anonymous identifiers
#   --include-surveys       Also process survey-type quizzes
#   --quiz-ids ID [ID ...]  Only process these specific quiz IDs
#   -n, --dry-run           Show what would be done without making changes
#   -v, --verbose           Show detailed output
#   -h, --help              Show this help message
#
# Session:      Canvas Quiz Database Creation
# AI Model:     Claude Opus 4.6
# Attribution:  Generated by Michael Gilchrist in collaboration with
#               ClaudeAI Opus 4.6
# ============================================================================

import argparse
import os
import re
import sys
import time
import urllib.error

from canvas_api import (
    create_quiz_report,
    get_progress,
    get_quiz,
    get_quiz_report,
    get_quizzes,
)
from canvas_http import http_get_raw
from io_utils import read_token
from report_to_csv import (
    anonymize_csv,
    extract_progress_id,
    flatten_newlines_in_csv,
    poll_until_complete,
    sanitize_for_filename,
)


def download_one_report(base_url, token, course_id, quiz_id, quiz_title,
                        report_type, includes_all_versions, poll_interval,
                        keep_newlines, anonymize, outdir, verbose):
    """Download a single quiz report CSV.  Returns (outpath, error_msg).
    On success error_msg is None; on failure outpath is None.
    """
    try:
        # Step 1: Trigger report
        if verbose:
            print(f"  [INFO] Triggering {report_type} report...")
        try:
            report = create_quiz_report(
                base_url, token, course_id, quiz_id,
                report_type=report_type,
                includes_all_versions=includes_all_versions,
                verbose=verbose)
        except urllib.error.HTTPError as e:
            if e.code == 409:
                if verbose:
                    print("  [WARN] Report already generating, retrying...")
                report = create_quiz_report(
                    base_url, token, course_id, quiz_id,
                    report_type=report_type,
                    includes_all_versions=includes_all_versions,
                    verbose=verbose)
            else:
                raise

        report_id = report.get("id")
        if report_id is None:
            return None, "No report id in API response"

        # Step 2: Poll progress
        progress_url = report.get("progress_url")
        file_obj = report.get("file")

        if file_obj and file_obj.get("url"):
            if verbose:
                print("  [INFO] Report already cached.")
        elif progress_url:
            progress_id = extract_progress_id(progress_url)
            if verbose:
                print(f"  [INFO] Polling progress {progress_id}...")
            poll_until_complete(base_url, token, progress_id,
                                poll_interval=poll_interval,
                                verbose=verbose)
            report = get_quiz_report(base_url, token, course_id,
                                     quiz_id, report_id, verbose=verbose)
            file_obj = report.get("file")
        else:
            return None, "No progress_url or file in response"

        if not file_obj or not file_obj.get("url"):
            return None, "Report completed but no file URL"

        # Step 3: Download CSV
        csv_bytes = http_get_raw(file_obj["url"])

        # Step 4: Post-process
        if not keep_newlines:
            csv_bytes = flatten_newlines_in_csv(csv_bytes)
        if anonymize:
            csv_bytes = anonymize_csv(csv_bytes)

        # Build filename
        today = time.strftime("%Y-%m-%d")
        report_label = report_type.replace("_", ".")
        quiz_slug = sanitize_for_filename(quiz_title) if quiz_title else ""
        if anonymize:
            ids_label = ""
        else:
            ids_label = f"_{course_id}-{quiz_id}"
        if quiz_slug:
            filename = f"{quiz_slug}_{report_label}{ids_label}_{today}.csv"
        else:
            filename = f"{report_label}{ids_label}_{today}.csv"

        os.makedirs(outdir, exist_ok=True)
        outpath = os.path.join(outdir, filename)
        with open(outpath, "wb") as f:
            f.write(csv_bytes)

        return outpath, None

    except Exception as e:
        return None, str(e)


def main():
    ap = argparse.ArgumentParser(
        description="Download quiz report CSVs for all quizzes in a course.")
    ap.add_argument("course_id", type=int,
                    help="Canvas course ID")

    ap.add_argument("--base-url", required=True,
                    help="Canvas instance URL "
                         "(e.g. https://utk.instructure.com)")
    ap.add_argument("--token", default=None,
                    help="Canvas API token (inline)")
    ap.add_argument("--token-file", default=None,
                    help="Path to file containing Canvas API token")

    ap.add_argument("--outdir", default=os.path.join("output", "CSV"),
                    help="Output directory for CSVs (default: output/CSV)")
    ap.add_argument("--report-type", default="student_analysis",
                    choices=["student_analysis", "item_analysis"],
                    help="Report type (default: student_analysis)")
    ap.add_argument("--all-versions", action="store_true",
                    help="Include all submission attempts")
    ap.add_argument("--poll-interval", type=int, default=5,
                    help="Seconds between progress polls (default: 5)")

    ap.add_argument("--keep-newlines", action="store_true",
                    help="Keep embedded newlines in CSV fields")
    ap.add_argument("--anonymize", action="store_true",
                    help="Replace student PII with anonymous identifiers")
    ap.add_argument("--include-surveys", action="store_true",
                    help="Also process survey-type quizzes")
    ap.add_argument("--quiz-ids", nargs="+", type=int, default=None,
                    help="Only process these specific quiz IDs")

    ap.add_argument("-n", "--dry-run", action="store_true",
                    help="Show what would be done without making changes")
    ap.add_argument("-v", "--verbose", action="store_true",
                    help="Show detailed output")

    args = ap.parse_args()

    token = read_token(args.token, args.token_file)
    base_url = args.base_url.rstrip("/")

    # Fetch quiz list
    print(f"Fetching quiz list for course {args.course_id}...")
    quizzes = get_quizzes(base_url, token, args.course_id,
                          verbose=args.verbose)

    # Filter to published quizzes
    quizzes = [q for q in quizzes if q.get("published")]

    # Filter out surveys unless requested
    if not args.include_surveys:
        quizzes = [q for q in quizzes
                   if q.get("quiz_type") != "survey"
                   and q.get("quiz_type") != "graded_survey"]

    # Filter to specific IDs if given
    if args.quiz_ids:
        id_set = set(args.quiz_ids)
        quizzes = [q for q in quizzes if q.get("id") in id_set]

    # Sort by title
    quizzes.sort(key=lambda q: q.get("title", ""))

    if not quizzes:
        print("No quizzes matched filters.")
        return

    print(f"Found {len(quizzes)} quizzes to process.\n")

    if args.dry_run:
        for q in quizzes:
            print(f"  [DRY RUN] Would download {args.report_type} for "
                  f"quiz {q['id']}: {q.get('title', '(untitled)')}")
        return

    # Process each quiz
    ok_count = 0
    fail_count = 0
    for i, q in enumerate(quizzes, 1):
        qid = q.get("id")
        title = q.get("title", "(untitled)")
        print(f"[{i}/{len(quizzes)}] Quiz {qid}: {title}")

        outpath, err = download_one_report(
            base_url=base_url,
            token=token,
            course_id=args.course_id,
            quiz_id=qid,
            quiz_title=title,
            report_type=args.report_type,
            includes_all_versions=args.all_versions,
            poll_interval=args.poll_interval,
            keep_newlines=args.keep_newlines,
            anonymize=args.anonymize,
            outdir=args.outdir,
            verbose=args.verbose,
        )

        if err:
            print(f"  [FAIL] {err}", file=sys.stderr)
            fail_count += 1
        else:
            print(f"  [OK] {outpath}")
            ok_count += 1

    print(f"\nDone: {ok_count} succeeded, {fail_count} failed "
          f"out of {len(quizzes)} quizzes.")


if __name__ == "__main__":
    main()
