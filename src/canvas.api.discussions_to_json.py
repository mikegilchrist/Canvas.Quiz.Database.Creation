#!/usr/bin/env python3
# ============================================================================
# Script:       canvas.api.discussions_to_json.py
# Version:      1.0.0
# Date:         2026-02-20
# Purpose:      Download Canvas discussion topics with full threaded views
#               (all entries, authors, messages) to JSON files.
#
# Usage:        canvas.api.discussions_to_json.py COURSE_ID [TOPIC_ID]
#                   [--base-url URL] [--token TOKEN | --token-file FILE]
#                   [--outdir DIR] [--anonymize] [--update]
#                   [--published-only] [--dry-run] [--verbose] [--help]
#
# Input:        Canvas API token + course_id (or ~/.canvas.api.conf)
# Output:       Per-topic directories with topic.json and view.json
#
# Options:
#   --base-url URL          Canvas instance URL (or set in ~/.canvas.api.conf)
#   --token TOKEN           Inline API token
#   --token-file FILE       Path to token file (or set in ~/.canvas.api.conf)
#   --outdir DIR            Output directory (default: output/Discussions)
#   --anonymize             Replace participant PII with anonymous identifiers
#   --published-only        Only process published topics (batch mode)
#   -u, --update            Skip topics whose output directory exists
#   -n, --dry-run           Show what would be done without making changes
#   -v, --verbose           Show detailed output
#   -h, --help              Show this help message
#
# Requirements:
#   - Python 3.7+
#   - Canvas API token with instructor/TA access to the course
#
# Session:      Canvas.API
# AI Model:     Claude Opus 4.6
# Attribution:  Generated by Michael Gilchrist in collaboration with
#               ClaudeAI Opus 4.6
# ============================================================================

import argparse
import json
import os
import sys

from canvas_api import (
    get_discussion_topic,
    get_discussion_topics,
    get_discussion_topic_view,
)
from io_utils import load_profile, read_token, sanitize_for_filename


# ---- Anonymization ----

def anonymize_view(view_data):
    """Return a copy of the view dict with participant PII removed.

    Replaces participant names with Student_01..NN and scrubs author
    references in entries.
    """
    anon = json.loads(json.dumps(view_data))  # deep copy

    # Build ID -> anonymous label mapping from participants
    participants = anon.get("participants", [])
    id_map = {}
    for i, p in enumerate(participants, 1):
        label = f"Student_{i:02d}"
        id_map[p.get("id")] = label
        p["display_name"] = label
        p.pop("avatar_url", None)
        p.pop("html_url", None)
        p.pop("pronouns", None)

    # Scrub entries recursively
    def scrub_entries(entries):
        if not entries:
            return
        for entry in entries:
            uid = entry.get("user_id")
            if uid in id_map:
                entry["user_name"] = id_map[uid]
            else:
                entry.pop("user_name", None)
            # Scrub nested replies
            scrub_entries(entry.get("replies", []))

    scrub_entries(anon.get("view", []))
    scrub_entries(anon.get("new_entries", []))

    return anon


# ---- Core download logic ----

def download_one_discussion(base_url, token, course_id, topic,
                            outdir, anonymize, update, verbose):
    """Download a single discussion topic and its full view.
    Returns (topic_dir, status_str) where status_str is one of:
    None (success), "skip" (--update), or an error message.
    """
    tid = topic["id"]
    title = topic.get("title", "(untitled)")
    slug = sanitize_for_filename(title)
    topic_dir = os.path.join(outdir, slug)

    # --update: skip if directory already exists
    if update and os.path.isdir(topic_dir):
        return topic_dir, "skip"

    try:
        # Fetch full threaded view
        view = get_discussion_topic_view(
            base_url, token, course_id, tid, verbose=verbose)

        os.makedirs(topic_dir, exist_ok=True)

        # Write topic metadata
        _write_json(os.path.join(topic_dir, "topic.json"), topic)

        # Write view (optionally anonymized)
        if anonymize:
            view = anonymize_view(view)
        _write_json(os.path.join(topic_dir, "view.json"), view)

        entry_count = len(view.get("view", []))
        participant_count = len(view.get("participants", []))
        if verbose:
            print(f"  [INFO] {participant_count} participants, "
                  f"{entry_count} top-level entries")

        return topic_dir, None

    except Exception as e:
        return None, str(e)


def _write_json(path, obj):
    """Write a JSON file with consistent formatting."""
    with open(path, "w", encoding="utf-8") as f:
        json.dump(obj, f, ensure_ascii=True, indent=2)


# ---- CLI ----

def main():
    ap = argparse.ArgumentParser(
        description="Download Canvas discussion topics with full threaded "
                    "views.  Pass a TOPIC_ID for a single topic, or omit "
                    "it to download all topics in the course.")
    ap.add_argument("course_id", type=int,
                    help="Canvas course ID")
    ap.add_argument("topic_id", nargs="?", type=int, default=None,
                    help="Discussion topic ID (omit for batch mode)")

    ap.add_argument("--base-url", default=None,
                    help="Canvas instance URL (or set base_url in "
                         "~/.canvas.api.conf)")
    ap.add_argument("--token", default=None,
                    help="Canvas API token (inline)")
    ap.add_argument("--token-file", default=None,
                    help="Path to token file (or set token_file in "
                         "~/.canvas.api.conf)")

    ap.add_argument("--outdir",
                    default=os.path.join("output", "Discussions"),
                    help="Output directory (default: output/Discussions)")

    ap.add_argument("--anonymize", action="store_true",
                    help="Replace participant PII with anonymous identifiers")
    ap.add_argument("--published-only", action="store_true",
                    help="Only process published topics (batch mode)")
    ap.add_argument("-u", "--update", action="store_true",
                    help="Skip topics whose output directory exists")

    ap.add_argument("-n", "--dry-run", action="store_true",
                    help="Show what would be done without making changes")
    ap.add_argument("-v", "--verbose", action="store_true",
                    help="Show detailed output")

    args = ap.parse_args()

    profile = load_profile()
    if not args.base_url:
        args.base_url = profile.get("base_url")
    if not args.base_url:
        ap.error("--base-url is required (or set base_url in "
                 "~/.canvas.api.conf)")
    token = read_token(args.token, args.token_file, profile)
    base_url = args.base_url.rstrip("/")

    # Build the list of topics to process
    if args.topic_id is not None:
        # Single-topic mode
        topic = get_discussion_topic(base_url, token, args.course_id,
                                     args.topic_id, verbose=args.verbose)
        topic_list = [topic]
    else:
        # Batch mode
        print(f"Fetching discussion topics for course {args.course_id}...")
        topic_list = get_discussion_topics(
            base_url, token, args.course_id, verbose=args.verbose)
        if args.published_only:
            topic_list = [t for t in topic_list if t.get("published")]
        topic_list.sort(key=lambda t: t.get("title", ""))

    if not topic_list:
        print("No discussion topics matched filters.")
        return

    if len(topic_list) > 1:
        print(f"Found {len(topic_list)} topics to process.\n")

    # Dry-run output
    if args.dry_run:
        for t in topic_list:
            tid = t.get("id", "?")
            title = t.get("title", "(untitled)")
            slug = sanitize_for_filename(title)
            tdir = os.path.join(args.outdir, slug)
            exists = os.path.isdir(tdir)
            skip_note = ("  [exists, would skip]"
                         if (args.update and exists) else "")
            print(f"  [DRY RUN] topic {tid}: {title}{skip_note}")
        return

    # Process each topic
    ok_count = 0
    skip_count = 0
    fail_count = 0
    total = len(topic_list)

    for i, t in enumerate(topic_list, 1):
        tid = t.get("id")
        title = t.get("title", "(untitled)")
        prefix = f"[{i}/{total}] " if total > 1 else ""
        print(f"{prefix}Topic {tid}: {title}")

        outpath, err = download_one_discussion(
            base_url=base_url,
            token=token,
            course_id=args.course_id,
            topic=t,
            outdir=args.outdir,
            anonymize=args.anonymize,
            update=args.update,
            verbose=args.verbose,
        )

        if err == "skip":
            print(f"  [SKIP] Already exists: {outpath}")
            skip_count += 1
        elif err:
            print(f"  [FAIL] {err}", file=sys.stderr)
            fail_count += 1
        else:
            print(f"  [OK] {outpath}")
            ok_count += 1

    # Summary for batch mode
    if total > 1:
        parts = [f"{ok_count} downloaded"]
        if skip_count:
            parts.append(f"{skip_count} skipped")
        if fail_count:
            parts.append(f"{fail_count} failed")
        print(f"\nDone: {', '.join(parts)} (of {total} topics).")


if __name__ == "__main__":
    main()
