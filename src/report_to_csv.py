#!/usr/bin/env python3
# ============================================================================
# Script:       report_to_csv.py
# Version:      1.2.0
# Date:         2026-02-19
# Purpose:      Download a Canvas Quiz Report (Student Analysis or Item
#               Analysis) as a CSV file via the Quiz Reports API.
#
# The Canvas Quiz Reports API is asynchronous:
#   1. POST to trigger report generation
#   2. Poll the Progress endpoint until complete
#   3. Fetch the report object to get the download URL
#   4. Download the CSV (no Authorization header -- verifier in URL)
#
# Usage:        report_to_csv.py COURSE_ID QUIZ_ID --base-url URL
#                   [--token TOKEN | --token-file FILE]
#                   [--outdir DIR] [--report-type TYPE]
#                   [--all-versions] [--poll-interval SEC]
#                   [--dry-run] [--verbose] [--help]
#
# Input:        Canvas API token + course_id + quiz_id
# Output:       CSV file in --outdir (default: output/CSV)
#
# Options:
#   --base-url URL          Canvas instance URL (required)
#   --token TOKEN           Inline API token
#   --token-file FILE       Path to file containing API token
#   --outdir DIR            Output directory (default: output/CSV)
#   --report-type TYPE      student_analysis (default) or item_analysis
#   --all-versions          Include all submission attempts, not just latest
#   --poll-interval SEC     Seconds between progress polls (default: 5)
#   --anonymize             Replace student PII with anonymous identifiers
#   -n, --dry-run           Show what would be done without making changes
#   -v, --verbose           Show detailed output
#   -h, --help              Show this help message
#
# Requirements:
#   - Python 3.7+
#   - Canvas API token with instructor/TA access to the course
#
# Session:      Canvas Quiz Database Creation
# AI Model:     Claude Opus 4.6
# Attribution:  Generated by Michael Gilchrist in collaboration with
#               ClaudeAI Opus 4.6
# ============================================================================

import argparse
import os
import re
import sys
import time
import urllib.error

from canvas_api import create_quiz_report, get_progress, get_quiz, get_quiz_report
from canvas_http import http_get_raw
from io_utils import read_token


def sanitize_for_filename(text, max_len=50):
    """Turn a quiz title into a filesystem-safe slug.

    Convention: underscores separate major sections, periods separate
    words within a section.

    Example: "S01: 2025-01-16 - Mutations/Teamwork"
          -> "S01_2025-01-16_Mutations.Teamwork"
    """
    text = text.strip()
    # Section separators (": ", " - ") become underscores
    text = re.sub(r'\s*:\s*', '_', text)
    text = re.sub(r'\s+-\s+', '_', text)
    # Slashes and commas become periods (within-topic separator)
    text = re.sub(r'[/,]+', '.', text)
    # Remaining spaces become periods (words within a section)
    text = re.sub(r'\s+', '.', text)
    # Strip characters unsafe for filenames
    text = re.sub(r'[\\*?"<>|]+', '', text)
    # Collapse runs of underscores or periods
    text = re.sub(r'_+', '_', text)
    text = re.sub(r'\.+', '.', text)
    # Remove trailing underscores/periods
    text = re.sub(r'[_.]+$', '', text)
    # Truncate cleanly
    if len(text) > max_len:
        text = text[:max_len].rstrip('_.')
    return text


def flatten_newlines_in_csv(csv_bytes):
    """Replace embedded newlines inside quoted CSV fields with spaces.
    This makes the CSV easier to work with in tools that don't fully
    support RFC 4180 multi-line quoted fields.
    Returns modified bytes (UTF-8).
    """
    import csv
    import io

    text = csv_bytes.decode("utf-8")
    reader = csv.reader(io.StringIO(text))
    rows = list(reader)

    out = io.StringIO()
    writer = csv.writer(out, lineterminator="\n")
    for row in rows:
        # Replace newlines within each cell with a space
        cleaned = [cell.replace("\n", " ").replace("\r", " ") for cell in row]
        writer.writerow(cleaned)

    return out.getvalue().encode("utf-8")


# Columns containing personally identifiable information.
# Canvas Student Analysis CSV layout: name, id, sis_id, section,
# section_id, section_sis_id, submitted, <question cols...>
_PII_COLUMNS = {"name", "id", "sis_id", "section", "section_id",
                "section_sis_id"}


def anonymize_csv(csv_bytes):
    """Replace student PII columns with anonymous identifiers.
    - name -> Student_01..Student_NN
    - id, sis_id, section, section_id, section_sis_id -> blank
    - Question ID prefixes (e.g. "7252969: ...") in headers -> "Q1: ..."
    Returns modified bytes (UTF-8).
    """
    import csv
    import io

    text = csv_bytes.decode("utf-8")
    reader = csv.reader(io.StringIO(text))
    rows = list(reader)
    if not rows:
        return csv_bytes

    header = rows[0]

    # Map column index -> column name for PII columns
    pii_indices = {i: h for i, h in enumerate(header) if h in _PII_COLUMNS}
    name_col = None
    for i, h in enumerate(header):
        if h == "name":
            name_col = i
            break

    # Replace Canvas question IDs in headers with sequential Q1, Q2, ...
    # Headers look like "7252969: The readings mention..."
    q_num = 0
    for i, h in enumerate(header):
        m = re.match(r'^\d+:\s*', h)
        if m:
            q_num += 1
            header[i] = f"Q{q_num}: {h[m.end():]}"

    out = io.StringIO()
    writer = csv.writer(out, lineterminator="\n")
    writer.writerow(header)

    student_num = 0
    for row in rows[1:]:
        if not row:
            continue
        student_num += 1
        for i in pii_indices:
            if i == name_col:
                row[i] = f"Student_{student_num:02d}"
            else:
                row[i] = ""
        writer.writerow(row)

    return out.getvalue().encode("utf-8")


def extract_progress_id(progress_url):
    """Pull the numeric progress id from a Canvas progress URL.
    Example: "https://canvas.example.com/api/v1/progress/12345" -> 12345
    """
    match = re.search(r"/progress/(\d+)", progress_url)
    if match:
        return int(match.group(1))
    raise ValueError(f"Could not parse progress id from URL: {progress_url}")


def poll_until_complete(base_url, token, progress_id,
                        poll_interval=5, verbose=False):
    """Poll the Progress endpoint until workflow_state is completed or failed.
    Returns the final Progress object.
    """
    while True:
        prog = get_progress(base_url, token, progress_id, verbose=verbose)
        state = prog.get("workflow_state", "unknown")
        completion = prog.get("completion", 0)

        if verbose:
            print(f"[INFO] Progress {progress_id}: "
                  f"state={state}, completion={completion}%")

        if state == "completed":
            return prog
        if state == "failed":
            msg = prog.get("message", "no message")
            raise RuntimeError(
                f"Report generation failed (progress {progress_id}): {msg}")

        time.sleep(poll_interval)


def main():
    ap = argparse.ArgumentParser(
        description="Download a Canvas Quiz Report (Student Analysis / "
                    "Item Analysis) as a CSV file.")
    ap.add_argument("course_id", type=int,
                    help="Canvas course ID")
    ap.add_argument("quiz_id", type=int,
                    help="Canvas quiz ID")

    ap.add_argument("--base-url", required=True,
                    help="Canvas instance URL (e.g. https://utk.instructure.com)")
    ap.add_argument("--token", default=None,
                    help="Canvas API token (inline)")
    ap.add_argument("--token-file", default=None,
                    help="Path to file containing Canvas API token")

    ap.add_argument("--outdir", default=os.path.join("output", "CSV"),
                    help="Output directory for the CSV (default: output/CSV)")
    ap.add_argument("--report-type", default="student_analysis",
                    choices=["student_analysis", "item_analysis"],
                    help="Report type (default: student_analysis)")
    ap.add_argument("--all-versions", action="store_true",
                    help="Include all submission attempts, not just the latest")
    ap.add_argument("--poll-interval", type=int, default=5,
                    help="Seconds between progress polls (default: 5)")

    ap.add_argument("--keep-newlines", action="store_true",
                    help="Keep embedded newlines in CSV fields (default: "
                         "flatten to spaces)")
    ap.add_argument("--anonymize", action="store_true",
                    help="Replace student PII (name, id, sis_id, section "
                         "columns) with anonymous identifiers")
    ap.add_argument("-n", "--dry-run", action="store_true",
                    help="Show what would be done without making changes")
    ap.add_argument("-v", "--verbose", action="store_true",
                    help="Show detailed output")

    args = ap.parse_args()

    token = read_token(args.token, args.token_file)
    base_url = args.base_url.rstrip("/")

    if args.verbose:
        print(f"[INFO] Course: {args.course_id}, Quiz: {args.quiz_id}")
        print(f"[INFO] Report type: {args.report_type}")
        print(f"[INFO] All versions: {args.all_versions}")

    if args.dry_run:
        print(f"[DRY RUN] Would POST to create {args.report_type} report "
              f"for course {args.course_id}, quiz {args.quiz_id}")
        print(f"[DRY RUN] Would poll progress until complete")
        print(f"[DRY RUN] Would download CSV to: {args.outdir}/")
        return

    # Step 1: Trigger report generation
    if args.verbose:
        print(f"[INFO] Triggering {args.report_type} report...")

    try:
        report = create_quiz_report(
            base_url, token, args.course_id, args.quiz_id,
            report_type=args.report_type,
            includes_all_versions=args.all_versions,
            verbose=args.verbose)
    except urllib.error.HTTPError as e:
        if e.code == 409:
            print("[WARN] Report is already being generated. "
                  "Retrying to fetch existing report...",
                  file=sys.stderr)
            # A 409 means a report is in progress.  Re-POST returns
            # the existing report object on some Canvas versions;
            # on others we need to list reports.  Try listing.
            report = create_quiz_report(
                base_url, token, args.course_id, args.quiz_id,
                report_type=args.report_type,
                includes_all_versions=args.all_versions,
                verbose=args.verbose)
        else:
            raise

    report_id = report.get("id")
    if report_id is None:
        print("[ERROR] No report id in API response.", file=sys.stderr)
        print(f"[DEBUG] Response: {report}", file=sys.stderr)
        sys.exit(1)

    if args.verbose:
        print(f"[INFO] Report id: {report_id}")

    # Step 2: Poll progress if the report is not already complete
    progress_url = report.get("progress_url")
    file_obj = report.get("file")

    if file_obj and file_obj.get("url"):
        # Report was already generated and cached by Canvas
        if args.verbose:
            print("[INFO] Report already available (cached).")
    elif progress_url:
        progress_id = extract_progress_id(progress_url)
        if args.verbose:
            print(f"[INFO] Polling progress {progress_id} "
                  f"every {args.poll_interval}s...")
        poll_until_complete(base_url, token, progress_id,
                            poll_interval=args.poll_interval,
                            verbose=args.verbose)

        # Step 3: Fetch the report object to get the file URL
        if args.verbose:
            print("[INFO] Fetching report with file attachment...")
        report = get_quiz_report(base_url, token, args.course_id,
                                 args.quiz_id, report_id,
                                 verbose=args.verbose)
        file_obj = report.get("file")
    else:
        print("[ERROR] No progress_url or file in report response.",
              file=sys.stderr)
        print(f"[DEBUG] Response: {report}", file=sys.stderr)
        sys.exit(1)

    if not file_obj or not file_obj.get("url"):
        print("[ERROR] Report completed but no file URL found.",
              file=sys.stderr)
        print(f"[DEBUG] Report: {report}", file=sys.stderr)
        sys.exit(1)

    download_url = file_obj["url"]

    # Fetch quiz title for the filename
    quiz_slug = ""
    try:
        quiz_obj = get_quiz(base_url, token, args.course_id, args.quiz_id,
                            verbose=args.verbose)
        quiz_title = quiz_obj.get("title", "")
        if quiz_title:
            quiz_slug = sanitize_for_filename(quiz_title)
            if args.verbose:
                print(f"[INFO] Quiz title: {quiz_title}")
    except Exception:
        if args.verbose:
            print("[WARN] Could not fetch quiz title; "
                  "using IDs only for filename.")

    # Build filename:
    #   {quiz_slug}_{report.type}_{course}-{quiz}_{date}.csv
    # e.g. S01_2025-01-16_Mutations.Teamwork_student.analysis_12345-67890_2026-02-19.csv
    # When --anonymize, omit course/quiz IDs from the filename.
    today = time.strftime("%Y-%m-%d")
    report_label = args.report_type.replace("_", ".")
    if args.anonymize:
        ids_label = ""
    else:
        ids_label = f"_{args.course_id}-{args.quiz_id}"
    if quiz_slug:
        filename = f"{quiz_slug}_{report_label}{ids_label}_{today}.csv"
    else:
        filename = f"{report_label}{ids_label}_{today}.csv"

    if args.verbose:
        print(f"[INFO] Downloading to: {filename}")

    # Step 4: Download the CSV (NO auth header -- verifier is in the URL)
    csv_bytes = http_get_raw(download_url)

    # Flatten embedded newlines unless --keep-newlines was given
    if not args.keep_newlines:
        csv_bytes = flatten_newlines_in_csv(csv_bytes)
        if args.verbose:
            print("[INFO] Flattened embedded newlines in CSV fields.")

    # Anonymize student PII if requested
    if args.anonymize:
        csv_bytes = anonymize_csv(csv_bytes)
        if args.verbose:
            print("[INFO] Anonymized student PII columns.")

    # Write to disk
    os.makedirs(args.outdir, exist_ok=True)
    outpath = os.path.join(args.outdir, filename)
    with open(outpath, "wb") as f:
        f.write(csv_bytes)

    print(f"[OK] Saved {len(csv_bytes)} bytes to {outpath}")


if __name__ == "__main__":
    main()
